{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d78c62b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "gpu_number = \"0\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_number\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as keras_backend\n",
    "import numpy as np\n",
    "\n",
    "gpu_on = True\n",
    "\n",
    "if gpu_on :\n",
    "    gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    for device in gpu_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    gpu_devices = tf.config.experimental.list_physical_devices(\"CPU\")\n",
    "\n",
    "print(gpu_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd5ef9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "sys.path.append(\"../../../../CNN_total/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "147465de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data num 1276 with 11 classes\n",
      "Total data num 76 with 11 classes\n",
      "Total data num 50 with 11 classes\n"
     ]
    }
   ],
   "source": [
    "from src.data_loader.classification_video import ClassifyDataloader\n",
    "from glob import glob\n",
    "\n",
    "task = \"classification\"\n",
    "data_set_name = \"detect_lvi\"\n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "on_memory = False\n",
    "augmentation_proba = 0.625\n",
    "target_size = None\n",
    "interpolation = \"bilinear\"\n",
    "# class_mode = \"binary\"\n",
    "class_mode = \"categorical\"\n",
    "dtype=\"float32\"\n",
    "\n",
    "train_folder_list = glob(f\"../data/2-2. Split png 64 frame/train/*/*\")\n",
    "valid_folder_list = glob(f\"../data/2-2. Split png 64 frame/valid/*/*\")\n",
    "test_folder_list = glob(f\"../data/2-2. Split png 64 frame/test/*/*\")\n",
    "\n",
    "label_list = os.listdir(f\"../data/2. Split png/train\")\n",
    "label_level = 1\n",
    "\n",
    "label_to_index_dict = {label:index for index, label in enumerate(label_list)}\n",
    "index_to_label_dict = {index:label for index, label in enumerate(label_list)}\n",
    "\n",
    "augmentation_policy_dict = {\n",
    "    \"positional\": False,\n",
    "    \"noise\": True,\n",
    "    \"elastic\": False,\n",
    "    \"randomcrop\": False,\n",
    "    \"brightness_contrast\": False,\n",
    "    \"color\": False,\n",
    "    \"to_jpeg\": False\n",
    "}\n",
    "\n",
    "common_arg_dict = {\n",
    "    \"label_to_index_dict\": label_to_index_dict,\n",
    "    \"label_level\": label_level,\n",
    "    \"augmentation_policy_dict\": augmentation_policy_dict,\n",
    "    \"preprocess_input\": \"-1~1\",\n",
    "    \"target_size\": target_size,\n",
    "    \"interpolation\": interpolation,\n",
    "    \"class_mode\": class_mode,\n",
    "    \"dtype\": dtype\n",
    "}\n",
    "\n",
    "train_data_loader = ClassifyDataloader(image_folder_list=train_folder_list,\n",
    "                                       batch_size=batch_size,\n",
    "                                       num_workers=num_workers,\n",
    "                                       on_memory=on_memory,\n",
    "                                       augmentation_proba=augmentation_proba,\n",
    "                                       shuffle=True,\n",
    "                                       **common_arg_dict\n",
    ")\n",
    "valid_data_loader = ClassifyDataloader(image_folder_list=valid_folder_list,\n",
    "                                       batch_size=batch_size,\n",
    "                                       num_workers=1,\n",
    "                                       on_memory=on_memory,\n",
    "                                       augmentation_proba=0,\n",
    "                                       shuffle=False,\n",
    "                                       **common_arg_dict\n",
    ")\n",
    "test_data_loader = ClassifyDataloader(image_folder_list=test_folder_list,\n",
    "                                       batch_size=1,\n",
    "                                       num_workers=1,\n",
    "                                       on_memory=False,\n",
    "                                       augmentation_proba=0,\n",
    "                                       shuffle=False,\n",
    "                                       **common_arg_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b70bc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 64, 240, 320, 3) (4, 11)\n",
      "(4, 64, 240, 320, 3) (4, 11)\n",
      "(4, 64, 240, 320, 3) (4, 11)\n",
      "(4, 64, 240, 320, 3) (4, 11)\n",
      "(4, 64, 240, 320, 3) (4, 11)\n",
      "-1.0 1.0\n",
      "0.0 1.0\n",
      "(4, 64, 240, 320, 3) (4, 11)\n",
      "(4, 64, 240, 320, 3) (4, 11)\n",
      "-1.0 1.0\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    data = train_data_loader[i]\n",
    "    print(data[0].shape, data[1].shape)\n",
    "\n",
    "print(np.min(data[0]), np.max(data[0]))\n",
    "print(np.min(data[1]), np.max(data[1]))\n",
    "\n",
    "for i in range(2):\n",
    "    data = valid_data_loader[i]\n",
    "    print(data[0].shape, data[1].shape)\n",
    "\n",
    "print(np.min(data[0]), np.max(data[0]))\n",
    "print(np.min(data[1]), np.max(data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc19e7d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer output shape: (None, 9600, 128)\n",
      "GAP shape: (None, 128)\n",
      "model param num: 5849715\n",
      "model input shape: (None, 64, 240, 320, 3)\n",
      "model output shape: (None, 11)\n"
     ]
    }
   ],
   "source": [
    "from src.model.vision_transformer.classfication import get_swin_classification_3d\n",
    "\n",
    "input_shape = (64, 240, 320, 3)\n",
    "last_channel_num = 11\n",
    "filter_num_begin = 64     # number of channels in the first downsampling block; it is also the number of embedded dimensions\n",
    "depth = 3                  # the depth of SwinUNET; depth=4 means three down/upsampling levels and a bottom level \n",
    "stack_num_per_depth = 2         # number of Swin Transformers per downsampling level\n",
    "patch_size = (4, 4, 4)        # Extract 4-by-4 patches from the input image. Height and width of the patch must be equal.\n",
    "stride_mode = \"same\"\n",
    "num_heads = [4, 8, 8, 8]   # number of attention heads per down/upsampling level\n",
    "window_size = [4, 2, 2, 2] # the size of attention window per down/upsampling level\n",
    "num_mlp = 128              # number of MLP nodes within the Transformer\n",
    "act = \"leakyrelu\"\n",
    "last_act = \"softmax\"\n",
    "shift_window = True          # Apply window shifting, i.e., Swin-MSA\n",
    "include_3d = True\n",
    "swin_v2 = True\n",
    "model = get_swin_classification_3d(input_shape, last_channel_num, \n",
    "                                  filter_num_begin, depth, stack_num_per_depth,\n",
    "                                  patch_size, stride_mode, num_heads, window_size, num_mlp,\n",
    "                                  act=act, last_act=last_act, shift_window=shift_window, \n",
    "                                   include_3d=include_3d, swin_v2=swin_v2)\n",
    "print(f\"model param num: {model.count_params()}\")\n",
    "print(f\"model input shape: {model.input.shape}\")\n",
    "print(f\"model output shape: {model.output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65777dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# YY/MM/dd\n",
    "today_str = today.strftime(\"%Y-%m-%d\")\n",
    "today_weight_path = f\"./result_daily/{task}/{data_set_name}/{today_str}/gpu_{gpu_number}/target_size_{target_size}/weights/\" \n",
    "today_image_path = f\"./result_daily/{task}/{data_set_name}/{today_str}/gpu_{gpu_number}/target_size_{target_size}/images/\"\n",
    "today_logs_path = f\"./result_daily/{task}/{data_set_name}/{today_str}/gpu_{gpu_number}/target_size_{target_size}/\"\n",
    "os.makedirs(today_weight_path, exist_ok=True)\n",
    "os.makedirs(today_logs_path, exist_ok=True)\n",
    "optimizer = Nadam(1e-4, clipnorm=1)\n",
    "\n",
    "save_c = ModelCheckpoint(\n",
    "    today_weight_path+\"/weights_{val_loss:.4f}_{loss:.4f}_{epoch:02d}.hdf5\",\n",
    "    monitor='val_loss',\n",
    "    verbose=0,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min')\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch <= 40:\n",
    "        new_lr = 2e-5\n",
    "    elif epoch <= 100:\n",
    "        new_lr = 2e-4\n",
    "    elif epoch <= 200:\n",
    "        new_lr = 2e-5\n",
    "    else:\n",
    "        new_lr = 2e-6\n",
    "    return new_lr\n",
    "scheduler_callback = LearningRateScheduler(scheduler, verbose=1)\n",
    "csv_logger = CSVLogger(f'{today_logs_path}/log.csv', append=False, separator=',')\n",
    "loss_function = CategoricalCrossentropy(label_smoothing=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66ad147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./result_total/weights_1.3406_0.4472_107.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678cfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 806s 2s/step - loss: 0.4395 - accuracy: 0.9067 - val_loss: 1.3396 - val_accuracy: 0.6053\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 462s 1s/step - loss: 0.4176 - accuracy: 0.9114 - val_loss: 1.3688 - val_accuracy: 0.5921\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 469s 1s/step - loss: 0.4407 - accuracy: 0.8997 - val_loss: 1.3382 - val_accuracy: 0.5789\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 476s 1s/step - loss: 0.4257 - accuracy: 0.9208 - val_loss: 1.3327 - val_accuracy: 0.6184\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 469s 1s/step - loss: 0.4272 - accuracy: 0.9122 - val_loss: 1.3324 - val_accuracy: 0.6053\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 463s 1s/step - loss: 0.4184 - accuracy: 0.9146 - val_loss: 1.4272 - val_accuracy: 0.5789\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 637s 2s/step - loss: 0.4253 - accuracy: 0.9083 - val_loss: 1.3501 - val_accuracy: 0.6053\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 502s 2s/step - loss: 0.4093 - accuracy: 0.9083 - val_loss: 1.3964 - val_accuracy: 0.5658\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 613s 2s/step - loss: 0.4192 - accuracy: 0.9044 - val_loss: 1.3167 - val_accuracy: 0.6579\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 523s 2s/step - loss: 0.4197 - accuracy: 0.9099 - val_loss: 1.3873 - val_accuracy: 0.5526\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 551s 2s/step - loss: 0.4067 - accuracy: 0.9130 - val_loss: 1.3420 - val_accuracy: 0.6316\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 587s 2s/step - loss: 0.4093 - accuracy: 0.9114 - val_loss: 1.3679 - val_accuracy: 0.5921\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 563s 2s/step - loss: 0.3931 - accuracy: 0.9240 - val_loss: 1.3435 - val_accuracy: 0.5789\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 570s 2s/step - loss: 0.4123 - accuracy: 0.9138 - val_loss: 1.3210 - val_accuracy: 0.6184\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 588s 2s/step - loss: 0.4163 - accuracy: 0.9146 - val_loss: 1.3261 - val_accuracy: 0.6184\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 510s 2s/step - loss: 0.4111 - accuracy: 0.9067 - val_loss: 1.4256 - val_accuracy: 0.6053\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 2e-05.\n",
      "175/319 [===============>..............] - ETA: 3:23 - loss: 0.3786 - accuracy: 0.9214"
     ]
    }
   ],
   "source": [
    "start_epoch = 107\n",
    "epochs = 300\n",
    "\n",
    "model.fit(\n",
    "    train_data_loader,\n",
    "    validation_data=valid_data_loader,\n",
    "    epochs=epochs,\n",
    "    callbacks=[scheduler_callback, save_c, csv_logger], \n",
    "    initial_epoch=start_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffe3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cdcbec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 553s 2s/step - loss: 0.8272 - accuracy: 0.7476 - val_loss: 1.5553 - val_accuracy: 0.5000\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 459s 1s/step - loss: 0.8483 - accuracy: 0.7335 - val_loss: 1.6355 - val_accuracy: 0.5000\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 452s 1s/step - loss: 0.7935 - accuracy: 0.7571 - val_loss: 1.9981 - val_accuracy: 0.3947\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 463s 1s/step - loss: 0.8042 - accuracy: 0.7461 - val_loss: 1.7087 - val_accuracy: 0.5132\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 465s 1s/step - loss: 0.7758 - accuracy: 0.7665 - val_loss: 1.6062 - val_accuracy: 0.5395\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 457s 1s/step - loss: 0.7702 - accuracy: 0.7696 - val_loss: 1.5353 - val_accuracy: 0.5132\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 470s 1s/step - loss: 0.7750 - accuracy: 0.7735 - val_loss: 1.5765 - val_accuracy: 0.4737\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 478s 1s/step - loss: 0.7586 - accuracy: 0.7735 - val_loss: 1.2582 - val_accuracy: 0.6447\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 480s 2s/step - loss: 0.7152 - accuracy: 0.7900 - val_loss: 1.7077 - val_accuracy: 0.4342\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 483s 2s/step - loss: 0.7239 - accuracy: 0.7688 - val_loss: 1.4229 - val_accuracy: 0.5132\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 475s 1s/step - loss: 0.6939 - accuracy: 0.7892 - val_loss: 1.4327 - val_accuracy: 0.5132\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 477s 1s/step - loss: 0.6852 - accuracy: 0.7970 - val_loss: 1.7643 - val_accuracy: 0.4605\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 473s 1s/step - loss: 0.6786 - accuracy: 0.8119 - val_loss: 1.3778 - val_accuracy: 0.6316\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 730s 2s/step - loss: 0.5298 - accuracy: 0.8676 - val_loss: 1.3668 - val_accuracy: 0.5658\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 498s 2s/step - loss: 0.4961 - accuracy: 0.8856 - val_loss: 1.3890 - val_accuracy: 0.6053\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 469s 1s/step - loss: 0.4660 - accuracy: 0.8981 - val_loss: 1.3350 - val_accuracy: 0.5921\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 472s 1s/step - loss: 0.4589 - accuracy: 0.8981 - val_loss: 1.4379 - val_accuracy: 0.5395\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 483s 2s/step - loss: 0.4431 - accuracy: 0.9060 - val_loss: 1.3671 - val_accuracy: 0.5921\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 516s 2s/step - loss: 0.4472 - accuracy: 0.8989 - val_loss: 1.3406 - val_accuracy: 0.5658\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 2e-05.\n",
      "111/319 [=========>....................] - ETA: 5:50 - loss: 0.4126 - accuracy: 0.9032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-83c1c1245d39>\", line 4, in <module>\n",
      "    model.fit(\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1184, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 885, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 917, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3039, in __call__\n",
      "    return graph_function._call_flat(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1963, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 591, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 744, in getmodule\n",
      "    for modname, module in sys.modules.copy().items():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-83c1c1245d39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2060\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2063\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "start_epoch = 88\n",
    "epochs = 300\n",
    "\n",
    "model.fit(\n",
    "    train_data_loader,\n",
    "    validation_data=valid_data_loader,\n",
    "    epochs=epochs,\n",
    "    callbacks=[scheduler_callback, save_c, csv_logger], \n",
    "    initial_epoch=start_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3a05c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 907s 3s/step - loss: 2.4803 - accuracy: 0.1089 - val_loss: 2.4427 - val_accuracy: 0.1053\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 489s 2s/step - loss: 2.3932 - accuracy: 0.1270 - val_loss: 2.3645 - val_accuracy: 0.1579\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 463s 1s/step - loss: 2.3711 - accuracy: 0.1364 - val_loss: 2.3952 - val_accuracy: 0.1053\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 448s 1s/step - loss: 2.3423 - accuracy: 0.1716 - val_loss: 2.4006 - val_accuracy: 0.1579\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 463s 1s/step - loss: 2.3325 - accuracy: 0.1810 - val_loss: 2.3421 - val_accuracy: 0.1579\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 479s 1s/step - loss: 2.2938 - accuracy: 0.1912 - val_loss: 2.3324 - val_accuracy: 0.1711\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 466s 1s/step - loss: 2.2662 - accuracy: 0.1998 - val_loss: 2.2736 - val_accuracy: 0.3421\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 463s 1s/step - loss: 2.2374 - accuracy: 0.2053 - val_loss: 2.2021 - val_accuracy: 0.3026\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 710s 2s/step - loss: 2.1911 - accuracy: 0.2281 - val_loss: 2.1997 - val_accuracy: 0.2500\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 682s 2s/step - loss: 2.1393 - accuracy: 0.2484 - val_loss: 2.2190 - val_accuracy: 0.2368\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 469s 1s/step - loss: 2.1198 - accuracy: 0.2398 - val_loss: 2.0654 - val_accuracy: 0.3947\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 466s 1s/step - loss: 2.0980 - accuracy: 0.2461 - val_loss: 2.0942 - val_accuracy: 0.2895\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 472s 1s/step - loss: 2.0907 - accuracy: 0.2665 - val_loss: 2.1418 - val_accuracy: 0.3289\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 460s 1s/step - loss: 2.0394 - accuracy: 0.2727 - val_loss: 2.0110 - val_accuracy: 0.3947\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 454s 1s/step - loss: 2.0181 - accuracy: 0.2970 - val_loss: 2.0440 - val_accuracy: 0.2763\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 445s 1s/step - loss: 1.9943 - accuracy: 0.2853 - val_loss: 2.0254 - val_accuracy: 0.4605\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 447s 1s/step - loss: 1.9545 - accuracy: 0.3182 - val_loss: 2.0199 - val_accuracy: 0.2895\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 444s 1s/step - loss: 1.9553 - accuracy: 0.2970 - val_loss: 2.1044 - val_accuracy: 0.2500\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 449s 1s/step - loss: 1.9411 - accuracy: 0.3119 - val_loss: 2.0047 - val_accuracy: 0.3421\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 451s 1s/step - loss: 1.9046 - accuracy: 0.3362 - val_loss: 1.9631 - val_accuracy: 0.3026\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 457s 1s/step - loss: 1.8950 - accuracy: 0.3323 - val_loss: 1.9972 - val_accuracy: 0.4211\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 452s 1s/step - loss: 1.8849 - accuracy: 0.3370 - val_loss: 1.9765 - val_accuracy: 0.3421\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 449s 1s/step - loss: 1.8584 - accuracy: 0.3511 - val_loss: 1.9561 - val_accuracy: 0.3684\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 454s 1s/step - loss: 1.8723 - accuracy: 0.3511 - val_loss: 1.9135 - val_accuracy: 0.4342\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 442s 1s/step - loss: 1.8441 - accuracy: 0.3582 - val_loss: 1.9508 - val_accuracy: 0.3553\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 456s 1s/step - loss: 1.8286 - accuracy: 0.3629 - val_loss: 1.9268 - val_accuracy: 0.2895\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 449s 1s/step - loss: 1.8369 - accuracy: 0.3582 - val_loss: 1.9557 - val_accuracy: 0.3684\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 445s 1s/step - loss: 1.8051 - accuracy: 0.3738 - val_loss: 1.9400 - val_accuracy: 0.4079\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 452s 1s/step - loss: 1.7946 - accuracy: 0.3785 - val_loss: 1.9469 - val_accuracy: 0.3684\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 453s 1s/step - loss: 1.7901 - accuracy: 0.3809 - val_loss: 1.9760 - val_accuracy: 0.4211\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 447s 1s/step - loss: 1.7747 - accuracy: 0.3934 - val_loss: 1.9915 - val_accuracy: 0.3289\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 459s 1s/step - loss: 1.7723 - accuracy: 0.4020 - val_loss: 1.8518 - val_accuracy: 0.3553\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 452s 1s/step - loss: 1.7751 - accuracy: 0.3895 - val_loss: 1.9382 - val_accuracy: 0.3158\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 454s 1s/step - loss: 1.7417 - accuracy: 0.4044 - val_loss: 2.0200 - val_accuracy: 0.2895\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 451s 1s/step - loss: 1.7534 - accuracy: 0.3981 - val_loss: 2.0183 - val_accuracy: 0.3289\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 457s 1s/step - loss: 1.7301 - accuracy: 0.4099 - val_loss: 1.9455 - val_accuracy: 0.3289\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 459s 1s/step - loss: 1.7381 - accuracy: 0.4107 - val_loss: 1.8751 - val_accuracy: 0.3816\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 454s 1s/step - loss: 1.7104 - accuracy: 0.4169 - val_loss: 1.8905 - val_accuracy: 0.3421\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 460s 1s/step - loss: 1.7206 - accuracy: 0.4138 - val_loss: 1.9158 - val_accuracy: 0.3289\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 457s 1s/step - loss: 1.7234 - accuracy: 0.4326 - val_loss: 1.8245 - val_accuracy: 0.4737\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 462s 1s/step - loss: 1.6827 - accuracy: 0.4271 - val_loss: 1.9743 - val_accuracy: 0.4474\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 461s 1s/step - loss: 2.0679 - accuracy: 0.2829 - val_loss: 1.9219 - val_accuracy: 0.4605\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 460s 1s/step - loss: 1.9218 - accuracy: 0.3354 - val_loss: 1.9846 - val_accuracy: 0.3289\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 459s 1s/step - loss: 1.8514 - accuracy: 0.3472 - val_loss: 1.9503 - val_accuracy: 0.3684\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 464s 1s/step - loss: 1.8292 - accuracy: 0.3691 - val_loss: 1.8919 - val_accuracy: 0.2632\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 456s 1s/step - loss: 1.7542 - accuracy: 0.4020 - val_loss: 1.8977 - val_accuracy: 0.3816\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 454s 1s/step - loss: 1.7262 - accuracy: 0.3981 - val_loss: 1.8840 - val_accuracy: 0.4474\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 458s 1s/step - loss: 1.7238 - accuracy: 0.4044 - val_loss: 1.8051 - val_accuracy: 0.3421\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 461s 1s/step - loss: 1.6880 - accuracy: 0.4099 - val_loss: 2.0056 - val_accuracy: 0.3816\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 452s 1s/step - loss: 1.6394 - accuracy: 0.4577 - val_loss: 1.9193 - val_accuracy: 0.2632\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 453s 1s/step - loss: 1.5936 - accuracy: 0.4530 - val_loss: 2.0352 - val_accuracy: 0.3026\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 461s 1s/step - loss: 1.5870 - accuracy: 0.4647 - val_loss: 1.9896 - val_accuracy: 0.3289\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 464s 1s/step - loss: 1.5569 - accuracy: 0.4851 - val_loss: 2.1033 - val_accuracy: 0.3158\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 462s 1s/step - loss: 1.5129 - accuracy: 0.5031 - val_loss: 2.0935 - val_accuracy: 0.3553\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 458s 1s/step - loss: 1.5028 - accuracy: 0.4976 - val_loss: 1.9819 - val_accuracy: 0.3553\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 461s 1s/step - loss: 1.4913 - accuracy: 0.5078 - val_loss: 1.9157 - val_accuracy: 0.2763\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 461s 1s/step - loss: 1.4577 - accuracy: 0.5196 - val_loss: 2.1219 - val_accuracy: 0.2500\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 462s 1s/step - loss: 1.4414 - accuracy: 0.5306 - val_loss: 1.9317 - val_accuracy: 0.4737\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 456s 1s/step - loss: 1.4320 - accuracy: 0.5118 - val_loss: 1.8655 - val_accuracy: 0.3421\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 459s 1s/step - loss: 1.3961 - accuracy: 0.5313 - val_loss: 1.8822 - val_accuracy: 0.3421\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 462s 1s/step - loss: 1.3670 - accuracy: 0.5462 - val_loss: 1.7756 - val_accuracy: 0.3553\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 457s 1s/step - loss: 1.3686 - accuracy: 0.5564 - val_loss: 1.9673 - val_accuracy: 0.3553\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 463s 1s/step - loss: 1.3487 - accuracy: 0.5502 - val_loss: 1.8437 - val_accuracy: 0.3421\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 463s 1s/step - loss: 1.3103 - accuracy: 0.5815 - val_loss: 1.9124 - val_accuracy: 0.3289\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 478s 1s/step - loss: 1.2918 - accuracy: 0.5823 - val_loss: 1.7968 - val_accuracy: 0.4474\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 481s 2s/step - loss: 1.2716 - accuracy: 0.5956 - val_loss: 1.7991 - val_accuracy: 0.3684\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 470s 1s/step - loss: 1.2472 - accuracy: 0.5972 - val_loss: 1.8892 - val_accuracy: 0.2895\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 469s 1s/step - loss: 1.2433 - accuracy: 0.5980 - val_loss: 1.8105 - val_accuracy: 0.4342\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 487s 2s/step - loss: 1.2341 - accuracy: 0.6152 - val_loss: 1.6938 - val_accuracy: 0.4605\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 473s 1s/step - loss: 1.2235 - accuracy: 0.6113 - val_loss: 1.8689 - val_accuracy: 0.3684\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 474s 1s/step - loss: 1.2053 - accuracy: 0.6058 - val_loss: 1.7049 - val_accuracy: 0.4342\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 478s 1s/step - loss: 1.1659 - accuracy: 0.6301 - val_loss: 1.7888 - val_accuracy: 0.3553\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 470s 1s/step - loss: 1.1438 - accuracy: 0.6293 - val_loss: 1.7161 - val_accuracy: 0.4474\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 502s 2s/step - loss: 1.1377 - accuracy: 0.6356 - val_loss: 1.7933 - val_accuracy: 0.4737\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 493s 2s/step - loss: 1.0944 - accuracy: 0.6340 - val_loss: 1.7963 - val_accuracy: 0.4211\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 503s 2s/step - loss: 1.0754 - accuracy: 0.6607 - val_loss: 1.5834 - val_accuracy: 0.5263\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.0002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 496s 2s/step - loss: 1.0767 - accuracy: 0.6583 - val_loss: 1.5982 - val_accuracy: 0.4342\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 504s 2s/step - loss: 1.0433 - accuracy: 0.6583 - val_loss: 1.6518 - val_accuracy: 0.4474\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 497s 2s/step - loss: 1.0085 - accuracy: 0.6795 - val_loss: 1.8981 - val_accuracy: 0.3947\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 483s 2s/step - loss: 1.0178 - accuracy: 0.6622 - val_loss: 1.6963 - val_accuracy: 0.4605\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 474s 1s/step - loss: 0.9876 - accuracy: 0.6842 - val_loss: 1.6773 - val_accuracy: 0.4737\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 476s 1s/step - loss: 1.0065 - accuracy: 0.6865 - val_loss: 1.6306 - val_accuracy: 0.4605\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 614s 2s/step - loss: 0.9685 - accuracy: 0.6936 - val_loss: 1.4148 - val_accuracy: 0.6316\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 797s 2s/step - loss: 0.9648 - accuracy: 0.7006 - val_loss: 1.7190 - val_accuracy: 0.4342\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 491s 2s/step - loss: 0.9181 - accuracy: 0.7139 - val_loss: 1.4002 - val_accuracy: 0.5921\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 470s 1s/step - loss: 0.9342 - accuracy: 0.7038 - val_loss: 1.4412 - val_accuracy: 0.4868\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 467s 1s/step - loss: 0.9054 - accuracy: 0.7132 - val_loss: 1.7762 - val_accuracy: 0.4079\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 471s 1s/step - loss: 0.8695 - accuracy: 0.7241 - val_loss: 1.4921 - val_accuracy: 0.5132\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.0002.\n",
      "  7/319 [..............................] - ETA: 7:31 - loss: 0.7663 - accuracy: 0.7143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-910277f0d9c3>\", line 4, in <module>\n",
      "    model.fit(\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1184, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 885, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 917, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3039, in __call__\n",
      "    return graph_function._call_flat(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1963, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 591, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 744, in getmodule\n",
      "    for modname, module in sys.modules.copy().items():\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-910277f0d9c3>\", line 4, in <module>\n",
      "    model.fit(\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1184, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 885, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 917, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3039, in __call__\n",
      "    return graph_function._call_flat(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1963, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 591, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3454, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-910277f0d9c3>\", line 4, in <module>\n",
      "    model.fit(\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1184, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 885, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 917, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3039, in __call__\n",
      "    return graph_function._call_flat(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1963, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 591, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3454, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3376, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1142, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "epochs = 300\n",
    "\n",
    "model.fit(\n",
    "    train_data_loader,\n",
    "    validation_data=valid_data_loader,\n",
    "    epochs=epochs,\n",
    "    callbacks=[scheduler_callback, save_c, csv_logger], \n",
    "    initial_epoch=start_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa1ab6db",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 454s 1s/step - loss: 2.0066 - accuracy: 0.3002 - val_loss: 1.8220 - val_accuracy: 0.3026\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 447s 1s/step - loss: 1.8806 - accuracy: 0.3386 - val_loss: 2.0395 - val_accuracy: 0.3026\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 448s 1s/step - loss: 1.8315 - accuracy: 0.3613 - val_loss: 1.7789 - val_accuracy: 0.3553\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.0002.\n",
      "319/319 [==============================] - 449s 1s/step - loss: 1.7770 - accuracy: 0.3864 - val_loss: 1.8897 - val_accuracy: 0.2500\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0002.\n",
      "254/319 [======================>.......] - ETA: 1:29 - loss: 1.7241 - accuracy: 0.3878"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-101ed339ba90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_epoch = 49\n",
    "epochs = 300\n",
    "\n",
    "model.fit(\n",
    "    train_data_loader,\n",
    "    validation_data=valid_data_loader,\n",
    "    epochs=epochs,\n",
    "    callbacks=[scheduler_callback, save_c, csv_logger], \n",
    "    initial_epoch=start_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96317651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 791s 2s/step - loss: 2.4700 - accuracy: 0.1121 - val_loss: 2.4352 - val_accuracy: 0.0789\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 488s 2s/step - loss: 2.3844 - accuracy: 0.1450 - val_loss: 2.3520 - val_accuracy: 0.1974\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 435s 1s/step - loss: 2.3606 - accuracy: 0.1497 - val_loss: 2.3582 - val_accuracy: 0.1711\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 441s 1s/step - loss: 2.3447 - accuracy: 0.1536 - val_loss: 2.2763 - val_accuracy: 0.2105\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 446s 1s/step - loss: 2.3204 - accuracy: 0.1740 - val_loss: 2.2825 - val_accuracy: 0.2368\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 446s 1s/step - loss: 2.2744 - accuracy: 0.1850 - val_loss: 2.2735 - val_accuracy: 0.1316\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 449s 1s/step - loss: 2.2593 - accuracy: 0.1818 - val_loss: 2.2404 - val_accuracy: 0.2763\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 455s 1s/step - loss: 2.2356 - accuracy: 0.2132 - val_loss: 2.2586 - val_accuracy: 0.1184\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 451s 1s/step - loss: 2.2098 - accuracy: 0.2265 - val_loss: 2.2256 - val_accuracy: 0.1974\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 447s 1s/step - loss: 2.1848 - accuracy: 0.2296 - val_loss: 2.1207 - val_accuracy: 0.3553\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 441s 1s/step - loss: 2.1501 - accuracy: 0.2335 - val_loss: 2.1670 - val_accuracy: 0.1842\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 446s 1s/step - loss: 2.1001 - accuracy: 0.2594 - val_loss: 2.1238 - val_accuracy: 0.2895\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 438s 1s/step - loss: 2.0868 - accuracy: 0.2735 - val_loss: 2.0893 - val_accuracy: 0.2632\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 442s 1s/step - loss: 2.0450 - accuracy: 0.2712 - val_loss: 2.1210 - val_accuracy: 0.1711\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 447s 1s/step - loss: 2.0275 - accuracy: 0.2680 - val_loss: 2.0271 - val_accuracy: 0.3026\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 441s 1s/step - loss: 1.9976 - accuracy: 0.3080 - val_loss: 1.9998 - val_accuracy: 0.3947\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 440s 1s/step - loss: 1.9843 - accuracy: 0.3072 - val_loss: 1.9911 - val_accuracy: 0.3158\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 451s 1s/step - loss: 1.9447 - accuracy: 0.3166 - val_loss: 1.9196 - val_accuracy: 0.2632\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 453s 1s/step - loss: 1.9424 - accuracy: 0.3354 - val_loss: 1.9108 - val_accuracy: 0.3289\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 454s 1s/step - loss: 1.9113 - accuracy: 0.3299 - val_loss: 1.9085 - val_accuracy: 0.3289\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 445s 1s/step - loss: 1.9146 - accuracy: 0.3213 - val_loss: 1.8734 - val_accuracy: 0.3684\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 451s 1s/step - loss: 1.8898 - accuracy: 0.3566 - val_loss: 1.9112 - val_accuracy: 0.3158\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 445s 1s/step - loss: 1.8922 - accuracy: 0.3542 - val_loss: 1.9449 - val_accuracy: 0.3026\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 445s 1s/step - loss: 1.8598 - accuracy: 0.3707 - val_loss: 1.9065 - val_accuracy: 0.3421\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 449s 1s/step - loss: 1.8528 - accuracy: 0.3644 - val_loss: 1.9246 - val_accuracy: 0.3421\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 450s 1s/step - loss: 1.8398 - accuracy: 0.3464 - val_loss: 1.9238 - val_accuracy: 0.2895\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 450s 1s/step - loss: 1.8301 - accuracy: 0.3699 - val_loss: 1.9125 - val_accuracy: 0.3289\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 448s 1s/step - loss: 1.8092 - accuracy: 0.3738 - val_loss: 1.9363 - val_accuracy: 0.3026\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 446s 1s/step - loss: 1.7962 - accuracy: 0.3887 - val_loss: 1.9536 - val_accuracy: 0.3421\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 447s 1s/step - loss: 1.8144 - accuracy: 0.3864 - val_loss: 1.9129 - val_accuracy: 0.2895\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 446s 1s/step - loss: 1.7767 - accuracy: 0.3926 - val_loss: 1.9170 - val_accuracy: 0.3421\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 451s 1s/step - loss: 1.7701 - accuracy: 0.3887 - val_loss: 1.9013 - val_accuracy: 0.3553\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 451s 1s/step - loss: 1.7444 - accuracy: 0.4122 - val_loss: 1.9607 - val_accuracy: 0.3026\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 446s 1s/step - loss: 1.7585 - accuracy: 0.4036 - val_loss: 1.8379 - val_accuracy: 0.3684\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 449s 1s/step - loss: 1.7436 - accuracy: 0.4091 - val_loss: 1.9108 - val_accuracy: 0.3816\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 453s 1s/step - loss: 1.7335 - accuracy: 0.4169 - val_loss: 1.8655 - val_accuracy: 0.3684\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 447s 1s/step - loss: 1.7283 - accuracy: 0.4185 - val_loss: 1.8528 - val_accuracy: 0.3947\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 457s 1s/step - loss: 1.7121 - accuracy: 0.4201 - val_loss: 1.8285 - val_accuracy: 0.4079\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 451s 1s/step - loss: 1.7261 - accuracy: 0.4036 - val_loss: 1.8453 - val_accuracy: 0.3421\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 449s 1s/step - loss: 1.7063 - accuracy: 0.4114 - val_loss: 1.8548 - val_accuracy: 0.4079\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 444s 1s/step - loss: 1.6822 - accuracy: 0.4216 - val_loss: 1.8854 - val_accuracy: 0.3289\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 463s 1s/step - loss: 1.6789 - accuracy: 0.4483 - val_loss: 1.9337 - val_accuracy: 0.3553\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 449s 1s/step - loss: 1.6926 - accuracy: 0.4279 - val_loss: 1.9513 - val_accuracy: 0.3421\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 456s 1s/step - loss: 1.6883 - accuracy: 0.4357 - val_loss: 1.9789 - val_accuracy: 0.3026\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 462s 1s/step - loss: 1.6538 - accuracy: 0.4350 - val_loss: 1.8859 - val_accuracy: 0.3684\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 469s 1s/step - loss: 1.6615 - accuracy: 0.4389 - val_loss: 1.8432 - val_accuracy: 0.3289\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 454s 1s/step - loss: 1.6454 - accuracy: 0.4483 - val_loss: 1.8350 - val_accuracy: 0.3816\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 455s 1s/step - loss: 1.6396 - accuracy: 0.4475 - val_loss: 1.8931 - val_accuracy: 0.3553\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 2e-05.\n",
      "319/319 [==============================] - 449s 1s/step - loss: 1.6159 - accuracy: 0.4624 - val_loss: 1.8103 - val_accuracy: 0.4342\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 2e-05.\n",
      " 57/319 [====>.........................] - ETA: 5:52 - loss: 1.6204 - accuracy: 0.4474"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-910277f0d9c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "epochs = 300\n",
    "\n",
    "model.fit(\n",
    "    train_data_loader,\n",
    "    validation_data=valid_data_loader,\n",
    "    epochs=epochs,\n",
    "    callbacks=[scheduler_callback, save_c, csv_logger], \n",
    "    initial_epoch=start_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eedd3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./weights_1.5013_0.5686_54.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83bb3ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data num 1276 with 11 classes\n",
      "Total data num 76 with 11 classes\n",
      "Total data num 50 with 11 classes\n"
     ]
    }
   ],
   "source": [
    "from src.data_loader.classification_video import ClassifyDataloader\n",
    "from glob import glob\n",
    "\n",
    "task = \"classification\"\n",
    "data_set_name = \"detect_lvi\"\n",
    "batch_size = 1\n",
    "num_workers = 1\n",
    "on_memory = False\n",
    "augmentation_proba = 0.625\n",
    "target_size = None\n",
    "interpolation = \"bilinear\"\n",
    "# class_mode = \"binary\"\n",
    "class_mode = \"categorical\"\n",
    "dtype=\"float32\"\n",
    "\n",
    "train_folder_list = glob(f\"../data/2. Split png/train/*/*\")\n",
    "valid_folder_list = glob(f\"../data/2. Split png/valid/*/*\")\n",
    "test_folder_list = glob(f\"../data/2. Split png/test/*/*\")\n",
    "\n",
    "label_list = os.listdir(f\"../data/2. Split png/train\")\n",
    "label_level = 1\n",
    "\n",
    "label_to_index_dict = {label:index for index, label in enumerate(label_list)}\n",
    "index_to_label_dict = {index:label for index, label in enumerate(label_list)}\n",
    "\n",
    "augmentation_policy_dict = {\n",
    "    \"positional\": False,\n",
    "    \"noise\": True,\n",
    "    \"elastic\": False,\n",
    "    \"randomcrop\": False,\n",
    "    \"brightness_contrast\": True,\n",
    "    \"color\": False,\n",
    "    \"to_jpeg\": False\n",
    "}\n",
    "\n",
    "common_arg_dict = {\n",
    "    \"label_to_index_dict\": label_to_index_dict,\n",
    "    \"label_level\": label_level,\n",
    "    \"augmentation_policy_dict\": augmentation_policy_dict,\n",
    "    \"preprocess_input\": \"-1~1\",\n",
    "    \"target_size\": target_size,\n",
    "    \"interpolation\": interpolation,\n",
    "    \"class_mode\": class_mode,\n",
    "    \"dtype\": dtype\n",
    "}\n",
    "\n",
    "train_data_loader = ClassifyDataloader(image_folder_list=train_folder_list,\n",
    "                                       batch_size=batch_size,\n",
    "                                       num_workers=num_workers,\n",
    "                                       on_memory=on_memory,\n",
    "                                       augmentation_proba=augmentation_proba,\n",
    "                                       shuffle=False,\n",
    "                                       **common_arg_dict\n",
    ")\n",
    "valid_data_loader = ClassifyDataloader(image_folder_list=valid_folder_list,\n",
    "                                       batch_size=batch_size,\n",
    "                                       num_workers=num_workers,\n",
    "                                       on_memory=on_memory,\n",
    "                                       augmentation_proba=0,\n",
    "                                       shuffle=False,\n",
    "                                       **common_arg_dict\n",
    ")\n",
    "test_data_loader = ClassifyDataloader(image_folder_list=test_folder_list,\n",
    "                                       batch_size=1,\n",
    "                                       num_workers=1,\n",
    "                                       on_memory=False,\n",
    "                                       augmentation_proba=0,\n",
    "                                       shuffle=False,\n",
    "                                       **common_arg_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "642aec0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/2. Split png/train\\BodyWeightSquats\\v_BodyWeightSquats_g01_c03\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(train_folder_list[idx])\n",
    "x, y = train_data_loader[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd146137",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9009490e-01 9.7977035e-02 7.6377107e-04 9.7597980e-01 5.7099175e-01\n",
      "  2.1920732e-01 9.8332834e-01 2.8068927e-01 2.1960255e-05 7.8363264e-01\n",
      "  9.8097897e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18570eca070>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "print(model(x).numpy())\n",
    "plt.plot(model(x).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ce03bc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduceLROnPlat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-238a97cbfd96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreduceLROnPlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsv_logger\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reduceLROnPlat' is not defined"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "epochs = 100\n",
    "\n",
    "model.fit(\n",
    "    train_data_loader,\n",
    "    validation_data=valid_data_loader,\n",
    "    epochs=epochs,\n",
    "    callbacks=[reduceLROnPlat, save_c, csv_logger],\n",
    "    initial_epoch=start_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c45716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9b775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
